# -*- coding: utf-8 -*-
"""Horizintal-FL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v-8_GCOc5unhuFXtHxGFUreBrE-ywWUM
"""

!pip install web3

from web3 import Web3

ganache_url = "https://8e90-105-111-244-247.ngrok-free.app"  # Mets ton IP publique ici
web3 = Web3(Web3.HTTPProvider(ganache_url))

print("Connexion r√©ussie :", web3.is_connected())

!pip install --quiet --upgrade tensorflow tensorflow-federated

import tensorflow as tf
import tensorflow_federated as tff
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from web3 import Web3
from sklearn.metrics import f1_score, precision_score, recall_score

# Connexion √† Web3 via Ngrok/Ganache
ganache_url = "https://8e90-105-111-244-247.ngrok-free.app"
web3 = Web3(Web3.HTTPProvider(ganache_url))

if web3.is_connected():
    print(" Connexion Web3 r√©ussie")
    accounts = web3.eth.accounts
else:
    raise ConnectionError(" Impossible de se connecter √† Web3 via Ngrok.")

# Charger le contrat
contract_address = "0x4a4Db684EDa5F9aE56B8Fb88F2D8D9668Ba9Aa30"  # Adresse du contrat
contract_abi = [
    {
        "anonymous": False,
        "inputs": [
            {
                "indexed": True,
                "internalType": "address",
                "name": "participant",
                "type": "address"
            }
        ],
        "name": "ConsentGiven",
        "type": "event"
    },
    {
        "inputs": [],
        "name": "giveConsent",
        "outputs": [],
        "stateMutability": "nonpayable",
        "type": "function"
    },
    {
        "inputs": [
            {
                "internalType": "address",
                "name": "participant",
                "type": "address"
            }
        ],
        "name": "checkConsent",
        "outputs": [
            {
                "internalType": "bool",
                "name": "",
                "type": "bool"
            }
        ],
        "stateMutability": "view",
        "type": "function"
    },
    {
        "inputs": [
            {
                "internalType": "address",
                "name": "",
                "type": "address"
            }
        ],
        "name": "hasConsented",
        "outputs": [
            {
                "internalType": "bool",
                "name": "",
                "type": "bool"
            }
        ],
        "stateMutability": "view",
        "type": "function"
    }
]
contract = web3.eth.contract(address=contract_address, abi=contract_abi)

# Liste d'adresses des clients autoris√©s
authorized_clients = [
     web3.eth.accounts[1],
     web3.eth.accounts[3],
     web3.eth.accounts[6],
     web3.eth.accounts[7],
     web3.eth.accounts[9]
]

# D√©finir un mod√®le Keras pour la r√©gression lin√©aire
def build_model():
    model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(8,)),
        tf.keras.layers.Dense(10, activation='relu'),
        tf.keras.layers.Dense(1)
    ])
    return model

# 2. Transformer le mod√®le Keras en un mod√®le TFF compatible
def model_fn():
    keras_model = build_model()#cree model
    input_spec = (
        tf.TensorSpec(shape=[None, 8], dtype=tf.float32),
        tf.TensorSpec(shape=[None, 1], dtype=tf.float32)
    )
    return tff.learning.models.from_keras_model(
        keras_model,
        input_spec=input_spec,
        loss=tf.keras.losses.MeanSquaredError(),
        metrics=[tf.keras.metrics.MeanSquaredError()]
    )

# 3. Pr√©traitement des donn√©es
def preprocess_data(data):
    X = data.drop('Outcome', axis=1).apply(pd.to_numeric, errors='coerce')
    y = data['Outcome'].apply(pd.to_numeric, errors='coerce')

    # Remplacer les valeurs manquantes  par la m√©diane
    X = X.fillna(X.median())
    y = y.fillna(y.median())

    # Assurez que X et y ont le m√™me nombre d'√©chantillons
    assert X.shape[0] == y.shape[0], f" Nombre d'√©chantillons incoh√©rent: X: {X.shape[0]}, y: {y.shape[0]}"

    # Normaliser les caract√©ristiques
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    return X_scaled.astype(np.float32), y.values.astype(np.float32)

# 4. Charger les donn√©es
url = '/content/drive/MyDrive/diabetes.csv'
columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']
data = pd.read_csv(url, header=0, names=columns)

# 5. Appliquer le pr√©traitement
X, y = preprocess_data(data)

# 6. V√©rifier les manquantes
assert not np.any(np.isnan(X)) and not np.any(np.isnan(y)), " Il reste des valeurs NaN !"

# Diviser les donn√©es en ensembles d'entra√Ænement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Convertir les donn√©es en TensorFlow Dataset pour l'entra√Ænement et les tests
train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32)
test_data = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)

# 7. Diviser les donn√©es en clients pour l'entra√Ænement f√©d√©r√©
def create_federated_data(X, y, num_clients=10):
    data_size = len(X)
    return [(X[i*(data_size//num_clients):(i+1)*(data_size//num_clients)],
             y[i*(data_size//num_clients):(i+1)*(data_size//num_clients)]) for i in range(num_clients)]

client_data = create_federated_data(X, y)

# 8. Pr√©parer les donn√©es pour TFF
def preprocess_for_tff(client_data):
    def to_dataset(data):
        x, y = data
        y = y.reshape(-1, 1)
        return tf.data.Dataset.from_tensor_slices((x, y)).batch(20)
    return [to_dataset(data) for data in client_data]

federated_data = preprocess_for_tff(client_data)

# 9. D√©finir les optimisateurs
client_optimizer_fn = lambda: tf.keras.optimizers.SGD(learning_rate=0.1)
server_optimizer_fn = lambda: tf.keras.optimizers.SGD(learning_rate=1.0)

# 10. Cr√©ation du processus d'apprentissage f√©d√©r√©
federated_training_process = tff.learning.algorithms.build_weighted_fed_avg(
    model_fn=model_fn,
    client_optimizer_fn=client_optimizer_fn,
    server_optimizer_fn=server_optimizer_fn
)

# 11. Initialiser le processus
state = federated_training_process.initialize()

# 12. V√©rifier si le client a donn√© son consentement
def client_has_given_consent(client_address):
    # V√©rifier si l'adresse du client est dans la liste des clients autoris√©s
    if client_address in authorized_clients:
        return True  # Consentement simul√©
    else:
        return False  # Consentement non donn√©

# 13. Entra√Ænement f√©d√©r√© avec calcul des m√©triques
accuracies = []
losses = []
f1_scores = []
precision_scores = []
recall_scores = []
num_rounds = 10

for round_num in range(1, num_rounds + 1):
    allowed_clients = []

    for i, (x, y) in enumerate(client_data):
        client_address = accounts[i % len(accounts)]  # Associer un compte al√©atoire

        if client_has_given_consent(client_address):
            print(f"‚úÖ Client {i+1} autoris√©")
            allowed_clients.append((x, y))
        else:
            print(f"‚ùå Client {i+1} NON autoris√© (pas de consentement)")

    # Si aucun client autoris√©, sauter l'it√©ration
    if not allowed_clients:
        print(f"‚ö†Ô∏è Aucun client autoris√© au Round {round_num}, passage au suivant...")
        continue

    # Pr√©parer les donn√©es des clients autoris√©s
    federated_data = preprocess_for_tff(allowed_clients)

    # Effectuer une it√©ration d'entra√Ænement
    state, metrics = federated_training_process.next(state, federated_data)

    # Extraire les m√©triques apr√©s chaque rand
    train_metrics = metrics['client_work']['train']
    loss = train_metrics.get('loss', 0.0)
    mse = train_metrics.get('mean_squared_error', 0.0)
    #sauvgarder les m√©triques
    accuracies.append(mse)
    losses.append(loss)

    # Reconstruction et mise √† jour du modele global
    final_keras_model = build_model()
    global_weights = federated_training_process.get_model_weights(state).trainable #recuperer poids globaux
    final_keras_model.set_weights(global_weights)

    # Pr√©dictions sur les donn√©es de test
    y_pred = (final_keras_model.predict(X_test) > 0.5).flatten()

    # Calculer les m√©triques
    f1 = f1_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)

    f1_scores.append(f1)
    precision_scores.append(precision)
    recall_scores.append(recall)

    print(f"Round {round_num} - Loss: {loss:.4f}, MSE: {mse:.4f}, F1-score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}")

# 14. Charger les poids globaux dans un mod√®le Keras pour √©valuation
final_keras_model = build_model()
global_weights = federated_training_process.get_model_weights(state).trainable
final_keras_model.set_weights(global_weights)


# Compiler et √©valuer le mod√®le final
final_keras_model.compile(optimizer='sgd', loss='mean_squared_error', metrics=['mean_squared_error'])
loss, mse = final_keras_model.evaluate(test_data, verbose=0)

# Pr√©dictions finales sur les donn√©es de test
y_pred_final = (final_keras_model.predict(X_test) > 0.5).flatten()

# Calcul des m√©triques finales
f1_final = f1_score(y_test, y_pred_final)
precision_final = precision_score(y_test, y_pred_final)
recall_final = recall_score(y_test, y_pred_final)

# Affichage du r√©sultat final global
print(f"\nüèÜ Final Global Model - Loss: {loss:.4f}, MSE: {mse:.4f}, F1-score: {f1_final:.4f}, Precision: {precision_final:.4f}, Recall: {recall_final:.4f}")